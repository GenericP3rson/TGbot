,words,ids,urls,messages
0,It,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
1,will,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
2,look,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
3,a,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
4,little,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
5,like,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
6,the,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
7,following.,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
8,I,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
9,recommend,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
10,the,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
11,GSQL101,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
12,course,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
13,to,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
14,get,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
15,a,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
16,primer,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
17,on,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
18,what,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
19,accumulators,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
20,are,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
21,and,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
22,how,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
23,they,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
24,work.,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
25,It,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
26,is,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
27,one,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
28,of,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
29,TG's,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
30,super-powers!,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
31,`CREATE,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
32,QUERY,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
33,Member_Count_Active_CAGs(String,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
34,Client_name),1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
35,FOR,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
36,GRAPH,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
37,CAG_Contract_Graph{`,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
38,SumAccum,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
39,<INT>,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
40,@@sum_CAGS;,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
41,#Begin,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
42,by,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
43,initializing,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
44,the,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
45,set,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
46,of,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
47,all,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
48,contracts,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
49,pp,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
50,=,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
51,{CAG.*};,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
52,#Get,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
53,the,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
54,number,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
55,of,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
56,specific,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
57,type,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
58,of,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
59,CAG,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
60,for,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
61,a,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
62,given,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
63,client,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
64,pp,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
65,=,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
66,SELECT,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
67,p,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
68,FROM,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
69,pp:p,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
70,WHERE,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
71,p.Search_Company,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
72,==,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
73,Client_name,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
74,and,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
75,p.Active_or_InActive,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
76,==,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
77,“Active”,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
78,POST-ACCUM,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
79,@@sum_CAGS,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
80,+=,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
81,p.Mbr_count;,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
82,PRINT,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
83,"""Total",1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
84,Member,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
85,Count,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
86,of,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
87,Active,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
88,CAGs,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
89,for,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
90,"""",1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
91,+,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
92,Client_name+,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
93,"""",1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
94,is,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
95,"""",1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
96,+,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
97,to_string(@@sum_CAGS);,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
98,PRINT,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
99,@@sum_CAGS;,1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
100,},1800,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"It will look a little like the following. I recommend the GSQL101 course to get a primer on what accumulators are and how they work. It is one of TG's super-powers!  `CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{`      SumAccum <INT> @@sum_CAGS;      #Begin by initializing the set of all contracts     pp = {CAG.*};      #Get the number of specific type of CAG for a given client     pp = SELECT p     FROM pp:p      WHERE p.Search_Company == Client_name and p.Active_or_InActive == “Active”     POST-ACCUM @@sum_CAGS += p.Mbr_count;      PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(@@sum_CAGS);     PRINT @@sum_CAGS;     }"
101,Hi,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
102,team,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
103,I,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
104,want,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
105,to,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
106,create,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
107,a,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
108,sum,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
109,over,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
110,a,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
111,vertex's,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
112,attribute.,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
113,I,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
114,have,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
115,vertex,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
116,as,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
117,"""CAG""",1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
118,and,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
119,it,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
120,has,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
121,attribute,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
122,"""Member",1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
123,"Count""",1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
124,.,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
125,Now,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
126,I,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
127,want,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
128,to,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
129,extract,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
130,the,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
131,sum,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
132,of,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
133,members,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
134,where,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
135,"""CAG""",1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
136,is,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
137,active.,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
138,I,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
139,have,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
140,written,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
141,following,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
142,query,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
143,but,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
144,its,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
145,throwing,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
146,error.,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
147,Can,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
148,anyone,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
149,help,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
150,me,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
151,with,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
152,that?,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
153,CREATE,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
154,QUERY,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
155,Member_Count_Active_CAGs(String,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
156,Client_name),1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
157,FOR,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
158,GRAPH,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
159,CAG_Contract_Graph{,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
160,#Begin,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
161,by,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
162,initializing,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
163,the,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
164,set,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
165,of,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
166,all,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
167,contracts,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
168,pp,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
169,=,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
170,{CAG.*};,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
171,#Get,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
172,the,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
173,number,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
174,of,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
175,specific,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
176,type,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
177,of,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
178,CAG,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
179,for,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
180,a,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
181,given,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
182,client,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
183,speific_CAGs,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
184,=,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
185,SELECT,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
186,sum(pp.Mbr_count),1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
187,FROM,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
188,pp:p,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
189,WHERE,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
190,pp.Search_Company,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
191,==,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
192,Client_name,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
193,and,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
194,pp.Active_or_InActive,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
195,==,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
196,"""Active"";",1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
197,PRINT,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
198,"""Total",1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
199,Member,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
200,Count,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
201,of,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
202,Active,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
203,CAGs,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
204,for,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
205,"""",1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
206,+,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
207,Client_name+,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
208,"""",1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
209,is,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
210,"""",1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
211,+,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
212,to_string(speific_CAGs);,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
213,PRINT,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
214,speific_CAGs;,1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
215,},1799,https://community.tigergraph.com/t/how-to-sum-over-a-vertexs-attribute/630,"Hi team   I want to create a sum over a vertex's attribute. I have vertex as ""CAG"" and it has attribute ""Member Count"" . Now I want to extract the sum of members where ""CAG"" is active. I have written following query but its throwing error. Can anyone help me with that?  CREATE QUERY Member_Count_Active_CAGs(String Client_name) FOR GRAPH CAG_Contract_Graph{   #Begin by initializing the set of all contracts   pp = {CAG.*};   #Get the number of specific type of CAG for a given client   speific_CAGs = SELECT sum(pp.Mbr_count) FROM pp:p WHERE pp.Search_Company == Client_name and pp.Active_or_InActive  == ""Active"";   PRINT ""Total Member Count of Active CAGs for "" + Client_name+ "" is "" + to_string(speific_CAGs);   PRINT speific_CAGs;   }"
216,Gotcha,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
217,:slight_smile:,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
218,Yeah,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
219,-,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
220,I,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
221,was,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
222,specifically,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
223,looking,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
224,for,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
225,a,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
226,way,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
227,to,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
228,"""debug""",1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
229,each,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
230,iteration,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
231,of,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
232,an,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
233,algorithm,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
234,so,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
235,I,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
236,wanted,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
237,to,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
238,inspect,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
239,how,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
240,each,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
241,iteration,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
242,effects,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
243,the,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
244,aggregators.,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
245,Thanks,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
246,a,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
247,lot,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
248,for,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
249,your,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
250,time,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
251,@rik,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
252,and,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
253,@mingxiwu!,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
254,I,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
255,really,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
256,appreciate,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
257,it!,1796,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"Gotcha :slight_smile: Yeah - I was specifically looking for a way to ""debug"" each iteration of an algorithm so I wanted to inspect how each iteration effects the aggregators.  Thanks a lot for your time @rik and @mingxiwu! I really appreciate it!"
258,This,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
259,was,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
260,really,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
261,interesting,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
262,as,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
263,it,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
264,demonstrates,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
265,an,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
266,enhancement,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
267,in,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
268,2.6,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
269,that,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
270,I,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
271,missed,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
272,but,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
273,it,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
274,really,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
275,makes,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
276,some,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
277,things,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
278,much,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
279,more,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
280,elegant.,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
281,You,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
282,can,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
283,apply,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
284,a,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
285,vertex,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
286,set,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
287,as,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
288,the,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
289,target,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
290,now.,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
291,If,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
292,you,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
293,use,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
294,the,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
295,global,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
296,accumulator,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
297,as-is,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
298,then,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
299,it,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
300,assumes,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
301,it,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
302,is,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
303,a,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
304,list,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
305,of,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
306,strings,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
307,defining,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
308,a,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
309,set,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
310,of,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
311,types,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
312,(which,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
313,was,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
314,an,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
315,enhancement,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
316,so,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
317,we,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
318,could,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
319,parameterise,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
320,the,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
321,types,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
322,for,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
323,our,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
324,standard,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
325,algorithms).,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
326,But,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
327,if,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
328,you,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
329,convert,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
330,the,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
331,accumulator,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
332,to,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
333,a,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
334,vertex,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
335,set,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
336,using,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
337,the,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
338,curly-bracket,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
339,syntax,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
340,then,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
341,you,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
342,can,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
343,use,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
344,it,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
345,directly.,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
346,This,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
347,fragment,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
348,is,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
349,legal,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
350,syntax:,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
351,SetAccum<Vertex>,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
352,@@target;,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
353,SetAccum<Vertex>,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
354,@@source;,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
355,source_vset,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
356,=,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
357,{@@source};,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
358,target_vset,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
359,=,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
360,{@@target};,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
361,frontier,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
362,=,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
363,SELECT,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
364,u,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
365,FROM,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
366,source_vset:u-()-target_vset:t;,1795,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,This was really interesting as it demonstrates an enhancement in 2.6 that I missed but it really makes some things much more elegant.   You can apply a vertex set as the target now. If you use the global accumulator as-is then it assumes it is a list of strings defining a set of types (which was an enhancement so we could parameterise the types for our standard algorithms).  But if you convert the accumulator to a vertex set using the curly-bracket syntax then you can use it directly. This fragment is legal syntax:      SetAccum<Vertex> @@target;     SetAccum<Vertex> @@source;     	     source_vset  = {@@source};     target_vset = {@@target};      frontier = SELECT u     FROM source_vset:u-()-target_vset:t;
367,Just,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
368,to,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
369,finish,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
370,off.,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
371,Nope.,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
372,I,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
373,wasn't,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
374,suggesting,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
375,the,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
376,log,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
377,approach,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
378,if,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
379,you,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
380,are,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
381,specifically,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
382,looking,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
383,to,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
384,apply,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
385,the,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
386,logging,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
387,function,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
388,then,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
389,MingXi's,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
390,solution,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
391,is,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
392,the,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
393,only,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
394,way,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
395,I,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
396,know,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
397,of.,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
398,Given,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
399,your,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
400,routine,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
401,doesn't,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
402,return,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
403,any,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
404,values,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
405,I,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
406,meant,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
407,to,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
408,use,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
409,the,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
410,actual,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
411,print,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
412,function,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
413,after,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
414,the,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
415,select,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
416,block,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
417,was,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
418,complete.,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
419,That,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
420,works,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
421,fine,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
422,with,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
423,vset's.,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
424,CREATE,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
425,QUERY,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
426,test(Vertex,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
427,Src),1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
428,FOR,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
429,GRAPH,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
430,fraud_detection_network,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
431,{,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
432,BOOL,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
433,debug,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
434,=,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
435,TRUE;,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
436,ListAccum<Vertex>,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
437,@@log_vertices;,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
438,start,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
439,=,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
440,{Src};,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
441,WHILE,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
442,start.size(),1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
443,>,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
444,0,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
445,limit,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
446,10,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
447,DO,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
448,start,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
449,=,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
450,SELECT,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
451,v,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
452,FROM,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
453,start:,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
454,s,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
455,-,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
456,(:e),1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
457,->,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
458,:v,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
459,POST-ACCUM,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
460,@@log_vertices,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
461,+=,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
462,v,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
463,END;,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
464,myVset,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
465,=,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
466,{@@log_vertices};,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
467,print,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
468,myVset;,1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
469,},1794,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Just to finish off. Nope. I wasn't suggesting the log approach if you are specifically looking to apply the logging function then MingXi's solution is the only way I know of.  Given your routine doesn't return any values I meant to use the actual print function after the select block was complete. That works fine with vset's.      CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	END;          myVset = {@@log_vertices};         print myVset;      }
470,Yeah,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
471,I,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
472,was,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
473,trying,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
474,to,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
475,avoid,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
476,that...,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
477,:smiley:,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
478,But,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
479,if,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
480,there's,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
481,no,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
482,way,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
483,to,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
484,print,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
485,the,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
486,whole,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
487,content,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
488,of,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
489,the,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
490,vertex,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
491,-,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
492,I'll,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
493,do,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
494,that!,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
495,Thanks!,1793,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Yeah I was trying to avoid that... :smiley: But if there's no way to print the whole content of the vertex - I'll do that! Thanks!
496,"[quote=""dsolow",1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
497,post:1,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
498,"topic:627""]",1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
499,```,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
500,SetAccum<Vertex>,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
501,@@target;,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
502,SetAccum<Vertex>,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
503,@@source;,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
504,source,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
505,(Any),1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
506,=,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
507,@@source;,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
508,frontier,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
509,=,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
510,SELECT,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
511,u,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
512,FROM,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
513,source:u-(shareholder_of:e)->(@@target):v;,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
514,```,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
515,[/quote],1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
516,You,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
517,might,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
518,try,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
519,this,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
520,for,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
521,your,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
522,goal.,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
523,SetAccum<Vertex>,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
524,@@target;,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
525,SetAccum<Vertex>,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
526,@@source;,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
527,source,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
528,(Any),1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
529,=,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
530,@@source;,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
531,frontier,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
532,=,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
533,SELECT,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
534,u,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
535,FROM,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
536,source:u,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
537,-,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
538,(shareholder_of:e),1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
539,->,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
540,:v,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
541,WHERE,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
542,v,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
543,in,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
544,@@target,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
545,ACCUM,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
546,xx;,1792,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ``` [/quote]  You might try this for your goal.   SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	               FROM source:u - (shareholder_of:e) -> :v                        WHERE v in @@target                        ACCUM xx;"
547,"[quote=""dsolow",1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
548,post:1,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
549,"topic:627""]",1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
550,```,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
551,a,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
552,global,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
553,SetAcum,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
554,accumulator,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
555,containing,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
556,a,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
557,set,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
558,of,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
559,edges,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
560,or,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
561,vertices,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
562,"(""@@""accumName)",1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
563,```,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
564,[/quote],1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
565,It's,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
566,a,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
567,doc,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
568,bug.,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
569,I,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
570,have,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
571,filed,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
572,a,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
573,ticket,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
574,internally.,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
575,In,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
576,syntax,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
577,V2,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
578,3.0,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
579,we,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
580,support,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
581,this,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
582,feature.,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
583,https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation,1791,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"[quote=""dsolow post:1 topic:627""] ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ``` [/quote]  It's a doc bug. I have filed a ticket internally.   In syntax V2 3.0 we support this feature. https://docs.tigergraph.com/start/gsql-102/multiple-hop-and-accumulation"
584,"[quote=""DenisK",1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
585,post:3,1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
586,"topic:624""]",1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
587,ur,1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
588,suggestion,1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
589,wouldn’t,1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
590,[/quote],1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
591,you,1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
592,can,1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
593,try,1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
594,to,1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
595,spell,1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
596,out,1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
597,the,1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
598,expressions.,1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
599,E.g.,1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
600,ACCUM,1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
601,log(true,1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
602,s.id,1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
603,s.@SampledEdges1,1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
604,s.@randomfactorList1,1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
605,s.@ModMap1,1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
606,randomfactor,1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
607,s.@ModMap1.get(randomfactor),1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
608,sampledEdges),1790,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"[quote=""DenisK post:3 topic:624""] ur suggestion wouldn’t [/quote]  you can try to spell out the expressions. E.g.   ACCUM  log(true s.id s.@SampledEdges1 s.@randomfactorList1 s.@ModMap1 randomfactor s.@ModMap1.get(randomfactor) sampledEdges)"
609,I'm,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
610,using,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
611,2.6.1.,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
612,In,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
613,the,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
614,docs,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
615,I,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
616,see,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
617,the,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
618,following:,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
619,https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
620,This,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
621,indicates,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
622,that,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
623,I,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
624,can,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
625,use,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
626,a,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
627,vertex,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
628,set,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
629,accum,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
630,like,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
631,this:,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
632,```,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
633,SetAccum<Vertex>,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
634,@@target;,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
635,SetAccum<Vertex>,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
636,@@source;,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
637,source,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
638,(Any),1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
639,=,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
640,@@source;,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
641,frontier,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
642,=,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
643,SELECT,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
644,u,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
645,FROM,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
646,source:u-(shareholder_of:e)->(@@target):v;,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
647,```,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
648,So,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
649,basically,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
650,I'm,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
651,looking,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
652,for,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
653,edges,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
654,between,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
655,two,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
656,sets.,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
657,However,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
658,this,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
659,gives,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
660,me,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
661,the,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
662,following,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
663,error:,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
664,```,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
665,(9,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
666,38),1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
667,Error:,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
668,@@target,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
669,is,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
670,not,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
671,string,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
672,or,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
673,set,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
674,of,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
675,string,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
676,expression,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
677,```,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
678,This,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
679,seems,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
680,to,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
681,indicate,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
682,that,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
683,only,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
684,a,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
685,set,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
686,of,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
687,strings,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
688,is,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
689,supported,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
690,even,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
691,though,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
692,the,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
693,docs,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
694,claim,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
695,a,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
696,set,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
697,of,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
698,vertices,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
699,is,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
700,supported:,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
701,```,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
702,a,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
703,global,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
704,SetAcum,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
705,accumulator,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
706,containing,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
707,a,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
708,set,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
709,of,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
710,edges,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
711,or,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
712,vertices,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
713,"(""@@""accumName)",1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
714,```,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
715,Any,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
716,idea,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
717,what's,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
718,wrong,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
719,here?,1789,https://community.tigergraph.com/t/using-vertex-set-accum-as-target-set/627,"I'm using 2.6.1. In the docs I see the following: https://docs.tigergraph.com/v/2.6/dev/gsql-ref/querying/select-statement#edge-set-and-target-vertex-set-options  This indicates that I can use a vertex set accum like this:  ``` 	SetAccum<Vertex> @@target; 	SetAccum<Vertex> @@source; 	 	source (Any) = @@source; 	 	frontier = SELECT u 	  FROM source:u-(shareholder_of:e)->(@@target):v; ```  So basically I'm looking for edges between two sets. However this gives me the following error: ``` (9 38) Error: @@target is not string or set of string expression ```  This seems to indicate that only a set of strings is supported even though the docs claim a set of vertices is supported:  ``` a global SetAcum accumulator containing a set of edges or vertices (""@@""accumName) ```  Any idea what's wrong here?"
720,Mmmm...,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
721,I,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
722,think,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
723,I'm,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
724,missing,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
725,something...,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
726,:slight_smile:,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
727,Do,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
728,you,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
729,mean,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
730,something,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
731,like,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
732,this?,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
733,```,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
734,CREATE,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
735,QUERY,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
736,test(Vertex,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
737,Src),1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
738,FOR,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
739,GRAPH,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
740,fraud_detection_network,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
741,{,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
742,BOOL,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
743,debug,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
744,=,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
745,TRUE;,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
746,ListAccum<Vertex>,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
747,@@log_vertices;,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
748,start,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
749,=,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
750,{Src};,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
751,WHILE,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
752,start.size(),1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
753,>,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
754,0,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
755,limit,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
756,10,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
757,DO,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
758,start,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
759,=,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
760,SELECT,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
761,v,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
762,FROM,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
763,start:,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
764,s,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
765,-,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
766,(:e),1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
767,->,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
768,:v,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
769,POST-ACCUM,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
770,@@log_vertices,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
771,+=,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
772,v,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
773,vset,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
774,=,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
775,{@@log_vertices},1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
776,LOG(debugvset);,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
777,END;,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
778,},1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
779,```,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
780,When,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
781,I,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
782,tried,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
783,it,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
784,I've,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
785,received,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
786,the,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
787,following,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
788,error,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
789,message:,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
790,![image|690x154,1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
791,100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png),1788,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Mmmm... I think I'm missing something... :slight_smile:   Do you mean something like this? ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	BOOL debug = TRUE; 	ListAccum<Vertex> @@log_vertices;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    POST-ACCUM 	      @@log_vertices += v 	      vset = {@@log_vertices} 	      LOG(debugvset); 	END; } ```  When I tried it I've received the following error message: ![image|690x154 100%](upload://fb9oxT7eXOlktpnFLV1MAsgfylu.png)
792,It,1786,https://community.tigergraph.com/t/debug-printing-vertices-content/624,It should work fine within ACCUM/POST-ACCUM. Unlike print which doesn't (unless you are printing to file).
793,should,1786,https://community.tigergraph.com/t/debug-printing-vertices-content/624,It should work fine within ACCUM/POST-ACCUM. Unlike print which doesn't (unless you are printing to file).
794,work,1786,https://community.tigergraph.com/t/debug-printing-vertices-content/624,It should work fine within ACCUM/POST-ACCUM. Unlike print which doesn't (unless you are printing to file).
795,fine,1786,https://community.tigergraph.com/t/debug-printing-vertices-content/624,It should work fine within ACCUM/POST-ACCUM. Unlike print which doesn't (unless you are printing to file).
796,within,1786,https://community.tigergraph.com/t/debug-printing-vertices-content/624,It should work fine within ACCUM/POST-ACCUM. Unlike print which doesn't (unless you are printing to file).
797,ACCUM/POST-ACCUM.,1786,https://community.tigergraph.com/t/debug-printing-vertices-content/624,It should work fine within ACCUM/POST-ACCUM. Unlike print which doesn't (unless you are printing to file).
798,Unlike,1786,https://community.tigergraph.com/t/debug-printing-vertices-content/624,It should work fine within ACCUM/POST-ACCUM. Unlike print which doesn't (unless you are printing to file).
799,print,1786,https://community.tigergraph.com/t/debug-printing-vertices-content/624,It should work fine within ACCUM/POST-ACCUM. Unlike print which doesn't (unless you are printing to file).
800,which,1786,https://community.tigergraph.com/t/debug-printing-vertices-content/624,It should work fine within ACCUM/POST-ACCUM. Unlike print which doesn't (unless you are printing to file).
801,doesn't,1786,https://community.tigergraph.com/t/debug-printing-vertices-content/624,It should work fine within ACCUM/POST-ACCUM. Unlike print which doesn't (unless you are printing to file).
802,(unless,1786,https://community.tigergraph.com/t/debug-printing-vertices-content/624,It should work fine within ACCUM/POST-ACCUM. Unlike print which doesn't (unless you are printing to file).
803,you,1786,https://community.tigergraph.com/t/debug-printing-vertices-content/624,It should work fine within ACCUM/POST-ACCUM. Unlike print which doesn't (unless you are printing to file).
804,are,1786,https://community.tigergraph.com/t/debug-printing-vertices-content/624,It should work fine within ACCUM/POST-ACCUM. Unlike print which doesn't (unless you are printing to file).
805,printing,1786,https://community.tigergraph.com/t/debug-printing-vertices-content/624,It should work fine within ACCUM/POST-ACCUM. Unlike print which doesn't (unless you are printing to file).
806,to,1786,https://community.tigergraph.com/t/debug-printing-vertices-content/624,It should work fine within ACCUM/POST-ACCUM. Unlike print which doesn't (unless you are printing to file).
807,file).,1786,https://community.tigergraph.com/t/debug-printing-vertices-content/624,It should work fine within ACCUM/POST-ACCUM. Unlike print which doesn't (unless you are printing to file).
808,Thanks,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
809,for,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
810,the,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
811,response,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
812,@rik!,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
813,If,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
814,I'm,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
815,not,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
816,mistaken,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
817,your,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
818,suggestion,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
819,wouldn't,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
820,work,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
821,inside,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
822,ACCUM,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
823,or,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
824,POST-ACCUM,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
825,clause...,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
826,Right?,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
827,I'm,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
828,interested,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
829,in,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
830,looking,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
831,into,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
832,what's,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
833,happening,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
834,during,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
835,each,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
836,iteration,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
837,of,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
838,the,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
839,WHILE,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
840,loop.,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
841,That's,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
842,why,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
843,I'm,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
844,using,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
845,the,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
846,LOG,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
847,command...,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
848,Any,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
849,idea,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
850,if,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
851,that's,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
852,possible?,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
853,:slight_smile:,1785,https://community.tigergraph.com/t/debug-printing-vertices-content/624,Thanks for the response @rik!  If I'm not mistaken your suggestion wouldn't work inside ACCUM or POST-ACCUM clause... Right?  I'm interested in looking into what's happening during each iteration of the WHILE loop. That's why I'm using the LOG command...  Any idea if that's possible? :slight_smile:
854,So,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
855,the,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
856,way,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
857,to,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
858,do,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
859,this,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
860,I,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
861,use,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
862,is,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
863,to,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
864,create,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
865,a,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
866,global,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
867,accumulator,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
868,and,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
869,add,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
870,the,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
871,relevant,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
872,vertices,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
873,to,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
874,that,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
875,say:,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
876,>,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
877,ListAccum,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
878,<VERTEX>,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
879,@@log_vertices,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
880,At,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
881,the,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
882,end,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
883,I'll,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
884,convert,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
885,that,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
886,into,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
887,a,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
888,vertex,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
889,set,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
890,and,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
891,then,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
892,print,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
893,that:,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
894,>,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
895,vset,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
896,=,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
897,{@@log_vertices};,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
898,>,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
899,print,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
900,vset;,1784,https://community.tigergraph.com/t/debug-printing-vertices-content/624,So the way to do this I use is to create a global accumulator and add the relevant vertices to that say:  > ListAccum <VERTEX> @@log_vertices  At the end I'll convert that into a vertex set and then print that:  > vset = {@@log_vertices}; > print vset;
901,In,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
902,order,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
903,to,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
904,debug,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
905,a,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
906,query,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
907,that,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
908,I'm,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
909,writing,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
910,I'd,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
911,like,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
912,to,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
913,be,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
914,able,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
915,to,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
916,display,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
917,the,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
918,content,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
919,of,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
920,the,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
921,vertices,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
922,that,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
923,have,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
924,been,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
925,traversed.,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
926,I'm,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
927,using,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
928,something,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
929,like,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
930,this:,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
931,```,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
932,CREATE,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
933,QUERY,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
934,test(Vertex,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
935,Src),1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
936,FOR,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
937,GRAPH,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
938,fraud_detection_network,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
939,{,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
940,BOOL,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
941,debug,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
942,=,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
943,TRUE;,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
944,start,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
945,=,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
946,{Src};,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
947,WHILE,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
948,start.size(),1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
949,>,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
950,0,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
951,limit,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
952,10,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
953,DO,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
954,start,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
955,=,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
956,SELECT,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
957,v,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
958,FROM,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
959,start:,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
960,s,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
961,-,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
962,(:e),1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
963,->,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
964,:v,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
965,ACCUM,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
966,//,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
967,some,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
968,logic...,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
969,POST-ACCUM,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
970,LOG(debugv);,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
971,END;,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
972,},1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
973,```,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
974,The,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
975,problem,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
976,is,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
977,that,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
978,it,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
979,only,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
980,prints,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
981,the,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
982,ID,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
983,of,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
984,the,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
985,vertex,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
986,which,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
987,is,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
988,expected,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
989,if,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
990,the,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
991,behavior,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
992,of,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
993,LOG,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
994,is,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
995,the,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
996,same,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
997,as,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
998,the,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
999,behavior,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
1000,of,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
1001,PRINT,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
1002,-,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
1003,https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
1004,Is,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
1005,there,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
1006,a,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
1007,way,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
1008,to,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
1009,print,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
1010,the,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
1011,"""whole",1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
1012,"content""",1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
1013,(i.e.,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
1014,attributes,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
1015,and,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
1016,accumulators),1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
1017,of,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
1018,a,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
1019,vertex?,1782,https://community.tigergraph.com/t/debug-printing-vertices-content/624,"In order to debug a query that I'm writing I'd like to be able to display the content of the vertices that have been traversed. I'm using something like this: ``` CREATE QUERY test(Vertex Src) FOR GRAPH fraud_detection_network {  	 	BOOL debug = TRUE;   	start = {Src}; 	WHILE start.size() > 0 limit 10 DO  	  start = SELECT v  	    FROM start: s - (:e) -> :v 	    ACCUM 	      // some logic... 	    POST-ACCUM 	      LOG(debugv); 	END; } ``` The problem is that it only prints the ID of the vertex which is expected if the behavior of LOG is the same as the behavior of PRINT - https://docs.tigergraph.com/dev/gsql-ref/querying/output-statements-and-file-objects#json-format-values.  Is there a way to print the ""whole content"" (i.e. attributes and accumulators) of a vertex?"
1020,"[quote=""Jon_Herke",1777,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,"[quote=""Jon_Herke post:3 topic:617""] GSQL [/quote]  great. we are schema first database."
1021,post:3,1777,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,"[quote=""Jon_Herke post:3 topic:617""] GSQL [/quote]  great. we are schema first database."
1022,"topic:617""]",1777,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,"[quote=""Jon_Herke post:3 topic:617""] GSQL [/quote]  great. we are schema first database."
1023,GSQL,1777,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,"[quote=""Jon_Herke post:3 topic:617""] GSQL [/quote]  great. we are schema first database."
1024,[/quote],1777,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,"[quote=""Jon_Herke post:3 topic:617""] GSQL [/quote]  great. we are schema first database."
1025,great.,1777,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,"[quote=""Jon_Herke post:3 topic:617""] GSQL [/quote]  great. we are schema first database."
1026,we,1777,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,"[quote=""Jon_Herke post:3 topic:617""] GSQL [/quote]  great. we are schema first database."
1027,are,1777,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,"[quote=""Jon_Herke post:3 topic:617""] GSQL [/quote]  great. we are schema first database."
1028,schema,1777,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,"[quote=""Jon_Herke post:3 topic:617""] GSQL [/quote]  great. we are schema first database."
1029,first,1777,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,"[quote=""Jon_Herke post:3 topic:617""] GSQL [/quote]  great. we are schema first database."
1030,database.,1777,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,"[quote=""Jon_Herke post:3 topic:617""] GSQL [/quote]  great. we are schema first database."
1031,@mingxiwu,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1032,we,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1033,figured,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1034,it,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1035,out.,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1036,You,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1037,need,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1038,to,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1039,**add,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1040,the,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1041,edge,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1042,to,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1043,the,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1044,schema**,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1045,before,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1046,you,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1047,can,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1048,use,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1049,the,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1050,INSERT,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1051,of,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1052,an,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1053,edge,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1054,in,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1055,your,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1056,GSQL.,1776,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,@mingxiwu we figured it out. You need to **add the edge to the schema** before you can use the INSERT of an edge in your GSQL.
1057,the,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1058,doc,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1059,of,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1060,shortestpath,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1061,is,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1062,a,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1063,built-in,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1064,query.,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1065,It's,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1066,not,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1067,written,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1068,by,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1069,GSQL.,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1070,If,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1071,you,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1072,use,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1073,GSQL,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1074,install,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1075,query,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1076,to,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1077,generate,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1078,the,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1079,endpoint,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1080,we,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1081,do,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1082,not,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1083,support,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1084,passing,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1085,parameter,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1086,by,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1087,json,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1088,using,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1089,POST,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1090,yet.,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1091,It's,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1092,coming,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1093,though.,1775,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,the doc of shortestpath is a built-in query. It's not written by GSQL. If you use GSQL install query to generate the endpoint we do not support passing parameter by json using POST yet. It's coming though.
1094,What,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1095,about,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1096,the,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1097,example,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1098,right,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1099,here:,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1100,https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1101,Looks,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1102,like,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1103,it's,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1104,using,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1105,POST,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1106,data,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1107,payload,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1108,to,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1109,specify,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1110,vertices:,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1111,```,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1112,curl,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1113,-s,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1114,-X,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1115,POST,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1116,'http://localhost:9000/shortestpath',1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1117,-d,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1118,'{,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1119,"""sources"":[{""type"":""VidUser""""id"":""2""}]",1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1120,"""targets"":[{""type"":""VidUser""""id"":""0""}",1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1121,"{""type"":""VidUser""""id"":""3""}]",1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1122,"""edgeFilters"":[{""type"":""User_Video""""condition"":""rating",1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1123,>,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1124,5,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1125,and,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1126,date_time,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1127,>,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1128,1000}],1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1129,"""maxLength"":4",1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1130,}',1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1131,```,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1132,Also,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1133,looks,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1134,like,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1135,there's,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1136,a,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1137,missing,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1138,quote,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1139,in,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1140,that,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1141,example.,1774,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"What about the example right here: https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#post-shortestpath-graphname-shortest-path-search  Looks like it's using POST data payload to specify vertices: ``` curl -s -X POST 'http://localhost:9000/shortestpath' -d '{   ""sources"":[{""type"":""VidUser""""id"":""2""}]   ""targets"":[{""type"":""VidUser""""id"":""0""} {""type"":""VidUser""""id"":""3""}]   ""edgeFilters"":[{""type"":""User_Video""""condition"":""rating > 5 and date_time > 1000}]   ""maxLength"":4 }' ```  Also looks like there's a missing quote in that example."
1142,If,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1143,the,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1144,REST++,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1145,server,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1146,is,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1147,local,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1148,then,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1149,server_ip,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1150,is,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1151,localhost.,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1152,The,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1153,request,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1154,can,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1155,use,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1156,either,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1157,the,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1158,GET,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1159,or,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1160,POST,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1161,method.,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1162,The,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1163,query,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1164,parameter,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1165,values,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1166,are,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1167,either,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1168,included,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1169,directly,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1170,in,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1171,the,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1172,query,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1173,string,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1174,of,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1175,the,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1176,HTTP,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1177,request's,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1178,URL,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1179,or,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1180,supplied,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1181,using,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1182,a,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1183,data,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1184,payload.,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1185,The,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1186,basic,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1187,format,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1188,for,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1189,the,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1190,parameters,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1191,as,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1192,a,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1193,query,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1194,string,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1195,is,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1196,param1=value&param2=value&param3=value,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1197,If,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1198,you,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1199,use,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1200,data,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1201,payload,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1202,JSON,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1203,format,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1204,only,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1205,support,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1206,GET.,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1207,We,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1208,are,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1209,developing,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1210,JSON,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1211,format,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1212,to,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1213,support,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1214,POST,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1215,in,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1216,the,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1217,next,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1218,minor,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1219,release,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1220,version.,1773,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,If the REST++ server is local then server_ip is localhost.   The request can use either the GET or POST method. The query parameter values are either included directly in the query string of the HTTP request's URL or supplied using a data payload. The basic format for the parameters as a query string is param1=value&param2=value&param3=value  If you use data payload JSON format only support GET. We are developing JSON format to support POST in the next minor release version.
1221,what's,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1222,the,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1223,schema,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1224,of,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1225,KNOWS?,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1226,Based,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1227,on,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1228,the,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1229,tutorial,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1230,https://docs.tigergraph.com/start/gsql-102/adv/dml,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1231,The,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1232,VALUES,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1233,clause,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1234,in,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1235,your,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1236,INSERT,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1237,statement,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1238,should,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1239,share,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1240,the,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1241,same,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1242,schema,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1243,of,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1244,KNOWS,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1245,edge.,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1246,Please,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1247,post,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1248,your,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1249,DDL,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1250,of,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1251,the,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1252,graph,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1253,schema,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1254,and,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1255,the,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1256,error,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1257,you,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1258,are,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1259,getting.,1772,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,what's the schema of KNOWS?  Based on the tutorial  https://docs.tigergraph.com/start/gsql-102/adv/dml The VALUES clause in your INSERT statement should share the same schema of KNOWS edge.   Please post your DDL of the graph schema and the error you are getting.
1260,Having,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1261,a,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1262,bit,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1263,of,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1264,trouble,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1265,figuring,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1266,out,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1267,how,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1268,to,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1269,pass,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1270,a,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1271,Vertex,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1272,parameter,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1273,via,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1274,HTTP,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1275,POST.,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1276,Here's,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1277,the,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1278,function,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1279,signature:,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1280,`CREATE,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1281,QUERY,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1282,delete_strategy_instance(VERTEX<IbisInstance>,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1283,instance),1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1284,syntax,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1285,v2,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1286,{`,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1287,I'm,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1288,doing,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1289,a,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1290,POST,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1291,with,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1292,"`{""instance"":",1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1293,"""test_delete_a1""}`",1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1294,And,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1295,I've,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1296,also,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1297,tried,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1298,"`{""instance"":",1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1299,"{""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}`",1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1300,And,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1301,I've,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1302,also,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1303,tried,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1304,"`{""instance"":",1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1305,"{""type"":""IbisInstance""""id"":""test_delete_a1""}}`",1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1306,Using,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1307,GET,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1308,works,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1309,but,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1310,I,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1311,want,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1312,to,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1313,make,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1314,sure,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1315,I,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1316,know,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1317,how,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1318,to,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1319,get,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1320,this,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1321,working,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1322,with,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1323,POST,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1324,for,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1325,future.,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1326,Any,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1327,advice?,1771,https://community.tigergraph.com/t/how-to-pass-vertex-id-as-a-parameter-via-post/620,"Having a bit of trouble figuring out how to pass a Vertex parameter via HTTP POST.  Here's the function signature:  `CREATE QUERY delete_strategy_instance(VERTEX<IbisInstance> instance) syntax v2 {`  I'm doing a POST with `{""instance"": ""test_delete_a1""}` And I've also tried `{""instance"": {""type"":""IbisInstance""""instance_name"":""test_delete_a1""}}` And I've also tried `{""instance"": {""type"":""IbisInstance""""id"":""test_delete_a1""}}`  Using GET works but I want to make sure I know how to get this working with POST for future. Any advice?"
1328,It;s,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1329,worth,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1330,noting,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1331,the,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1332,technique,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1333,here.,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1334,Static,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1335,accumulators,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1336,are,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1337,used,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1338,as,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1339,a,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1340,cache,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1341,and,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1342,retain,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1343,their,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1344,contents,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1345,across,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1346,invocations.,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1347,The,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1348,weights,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1349,here,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1350,are,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1351,being,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1352,held,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1353,in,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1354,a,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1355,file,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1356,the,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1357,scoring,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1358,routine,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1359,itself,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1360,is,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1361,expressed,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1362,as,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1363,a,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1364,user-defined,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1365,query.,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1366,The,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1367,weights,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1368,here,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1369,are,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1370,loaded,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1371,as,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1372,a,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1373,file,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1374,but,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1375,could,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1376,just,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1377,as,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1378,easily,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1379,be,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1380,held,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1381,in,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1382,the,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1383,database,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1384,and,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1385,loaded,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1386,from,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1387,there.,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1388,Ref,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1389,my,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1390,current,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1391,ML,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1392,work,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1393,I'm,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1394,looking,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1395,at,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1396,how,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1397,we,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1398,can,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1399,integrate,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1400,catboost,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1401,into,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1402,TG,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1403,and,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1404,load,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1405,trained,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1406,models,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1407,into,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1408,that.,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1409,This,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1410,may,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1411,take,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1412,a,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1413,week,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1414,or,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1415,two,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1416,to,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1417,get,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1418,working.,1768,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,It;s worth noting the technique here.  Static accumulators are used as a cache and retain their contents across invocations. The weights here are being held in a file the scoring routine itself is expressed as a user-defined query.  The weights here are loaded as a file but could just as easily be held in the database and loaded from there.  Ref my current ML work I'm looking at how we can integrate catboost into TG and load trained models into that. This may take a week or two to get working.
1419,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png),1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1420,Hi,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1421,all,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1422,do,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1423,not,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1424,know,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1425,if,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1426,this,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1427,is,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1428,the,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1429,correct,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1430,way,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1431,of,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1432,doing,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1433,it,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1434,but,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1435,I,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1436,am,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1437,currently,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1438,trying,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1439,to,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1440,create,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1441,an,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1442,edge,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1443,between,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1444,two,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1445,vertices,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1446,(of,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1447,different,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1448,types),1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1449,that,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1450,have,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1451,a,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1452,common,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1453,vertex,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1454,between,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1455,them.,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1456,I,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1457,seem,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1458,to,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1459,not,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1460,be,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1461,understanding,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1462,the,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1463,syntax,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1464,correctly,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1465,and,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1466,have,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1467,errors.,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1468,Can,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1469,someone,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1470,point,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1471,me,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1472,in,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1473,the,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1474,right,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1475,direction?,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1476,Thanks,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1477,in,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1478,advance.,1767,https://community.tigergraph.com/t/adding-edge-between-two-vertices-that-are-connected-by-common-vertex/617,![screenshot|690x388](upload://t4MVpWaqH542tbt6V6jZk1Zkj09.png)   Hi all do not know if this is the correct way of doing it but I am currently trying to create an edge between two vertices (of different types) that have a common vertex between them. I seem to not be understanding the syntax correctly and have errors. Can someone point me in the right direction? Thanks in advance.
1479,@Maatdeamon,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1480,You,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1481,can,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1482,use,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1483,LOADACCUM,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1484,to,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1485,load,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1486,parameter,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1487,files,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1488,into,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1489,a,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1490,global,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1491,accumulator.,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1492,And,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1493,the,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1494,loaded,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1495,global,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1496,accumulator,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1497,can,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1498,invoke,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1499,an,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1500,expression,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1501,function,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1502,to,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1503,do,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1504,the,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1505,scoring.,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1506,-,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1507,LOADACCUM,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1508,doc,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1509,is,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1510,here,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1511,https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1512,-,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1513,User-defined,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1514,expression,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1515,function,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1516,doc,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1517,is,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1518,here,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1519,https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1520,E.g.,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1521,below,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1522,is,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1523,a,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1524,query,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1525,we,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1526,used,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1527,to,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1528,do,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1529,scoring.,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1530,TigerGraph,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1531,is,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1532,used,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1533,to,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1534,collect,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1535,graph,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1536,feature,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1537,and,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1538,we,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1539,got,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1540,the,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1541,trained,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1542,classifier,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1543,parameter,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1544,from,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1545,external,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1546,ML,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1547,tools,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1548,and,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1549,load,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1550,them,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1551,into,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1552,global,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1553,accumulators,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1554,and,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1555,for,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1556,a,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1557,new,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1558,phone,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1559,we,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1560,collect,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1561,its,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1562,graph,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1563,features,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1564,and,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1565,called,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1566,the,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1567,user-define,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1568,scoring,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1569,function,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1570,with,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1571,the,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1572,classifier,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1573,parameters,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1574,and,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1575,the,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1576,newly,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1577,collected,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1578,features.,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1579,CREATE,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1580,QUERY,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1581,scoringMethod(vertex<phone>,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1582,phoneId,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1583,string,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1584,inputPath,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1585,=,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1586,"""/tmp/lgweight.configure""",1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1587,string,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1588,internalClusterFileName,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1589,=,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1590,"""/tmp/kMeanWeight_internal.csv""",1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1591,string,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1592,externalClusterFileName,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1593,=,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1594,"""/tmp/kMeanWeight_external.csv""",1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1595,bool,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1596,reloadWeightInfo,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1597,=,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1598,false,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1599,string,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1600,configFileName,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1601,=,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1602,"""/tmp/collectFeatures.config""",1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1603,bool,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1604,reloadConfig,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1605,=,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1606,false,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1607,int,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1608,numOfTopFriends,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1609,=,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1610,5,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1611,float,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1612,abnormalThreshold,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1613,=,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1614,0.5,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1615,float,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1616,advertisementThreshold,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1617,=,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1618,0.5,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1619,bool,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1620,usePrint,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1621,=,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1622,true),1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1623,for,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1624,graph,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1625,testGraph,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1626,returns,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1627,(ListAccum<float>),1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1628,{,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1629,TYPEDEF,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1630,tuple<float,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1631,weight,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1632,float,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1633,scale,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1634,float,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1635,mean>,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1636,ParamInfo;,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1637,ListAccum<float>,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1638,@@featureList;,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1639,ListAccum<float>,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1640,@@scoreList;,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1641,int,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1642,isExternal,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1643,=,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1644,0;,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1645,int,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1646,fraudFlag,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1647,=,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1648,-1;,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1649,static,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1650,ListAccum<ParamInfo>,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1651,@@paramInfo0;,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1652,static,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1653,ListAccum<ParamInfo>,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1654,@@paramInfo1;,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1655,static,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1656,ListAccum<ParamInfo>,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1657,@@paramInfo2;,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1658,static,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1659,ListAccum<ParamInfo>,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1660,@@paramInfo3;,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1661,static,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1662,ListAccum<ListAccum<float>,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1663,>,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1664,@@InternalCluster;,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1665,static,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1666,ListAccum<ListAccum<float>,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1667,>,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1668,@@ExternalCluster;,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1669,if,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1670,(@@paramInfo0.size(),1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1671,==,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1672,0,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1673,or,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1674,reloadWeightInfo,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1675,==,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1676,true),1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1677,{,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1678,@@paramInfo0.clear();,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1679,@@paramInfo0,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1680,=,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1681,{loadAccum(inputPath,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1682,"$0$1$2""""",1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1683,false)};,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1684,@@paramInfo1.clear();,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1685,@@paramInfo1,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1686,=,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1687,{loadAccum(inputPath,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1688,"$3$4$5""""",1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1689,false)};,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1690,@@paramInfo2.clear();,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1691,@@paramInfo2,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1692,=,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1693,{loadAccum(inputPath,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1694,"$6$7$8""""",1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1695,false)};,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1696,@@paramInfo3.clear();,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1697,@@paramInfo3,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1698,=,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1699,{loadAccum(inputPath,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1700,"$9$10$11""""",1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1701,false)};,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1702,},1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1703,if,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1704,(@@InternalCluster.size(),1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1705,==,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1706,0,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1707,or,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1708,reloadWeightInfo,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1709,==,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1710,true),1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1711,{,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1712,@@InternalCluster.clear();,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1713,@@InternalCluster,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1714,=,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1715,loadClusterInfo(internalClusterFileName);,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1716,@@ExternalCluster.clear();,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1717,@@ExternalCluster,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1718,=,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1719,loadClusterInfo(externalClusterFileName);,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1720,},1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1721,//call,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1722,another,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1723,gsql,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1724,query,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1725,to,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1726,collect,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1727,features,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1728,@@featureList,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1729,=,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1730,collectFeaturesR(phoneId,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1731,configFileName,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1732,reloadConfig,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1733,numOfTopFriends,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1734,false);,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1735,//obtain,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1736,the,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1737,last,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1738,element,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1739,of,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1740,featureList,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1741,which,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1742,indicates,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1743,isExternal,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1744,isExternal,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1745,=,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1746,@@featureList.get(69);,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1747,//scoring,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1748,by,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1749,calling,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1750,an,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1751,user,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1752,defined,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1753,expression,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1754,function.,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1755,score(phoneId,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1756,@@featureList,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1757,abnormalThreshold,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1758,advertisementThreshold,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1759,@@paramInfo0,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1760,@@paramInfo1,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1761,@@paramInfo2,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1762,@@paramInfo3,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1763,@@scoreList);,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1764,//set,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1765,the,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1766,initial,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1767,scamCluster,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1768,as,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1769,-1,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1770,which,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1771,means,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1772,not,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1773,a,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1774,valid,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1775,scam,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1776,@@scoreList,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1777,+=,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1778,-1;,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1779,//Get,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1780,the,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1781,fraud,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1782,flag,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1783,out,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1784,fraudFlag,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1785,=,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1786,@@scoreList.get(0);,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1787,if,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1788,(fraudFlag,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1789,==,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1790,3),1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1791,{,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1792,if,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1793,(isExternal,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1794,==,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1795,0),1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1796,{,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1797,updateScamClusterFlag(@@featureList,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1798,@@InternalCluster,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1799,@@scoreList);,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1800,},1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1801,else,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1802,{,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1803,updateScamClusterFlag(@@featureList,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1804,@@ExternalCluster,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1805,@@scoreList);,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1806,},1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1807,},1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1808,if,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1809,(usePrint),1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1810,{,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1811,print,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1812,@@scoreList;,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1813,},1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1814,return,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1815,@@scoreList;,1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1816,},1764,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,"@Maatdeamon  You can use LOADACCUM to load parameter files into a global accumulator. And the loaded global accumulator can invoke an expression function to do the scoring.   - LOADACCUM doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/declaration-and-assignment-statements#loadaccum-statement - User-defined expression function doc is here https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions   E.g.  below is a query we used to do scoring. TigerGraph is used to collect graph feature and we got the trained classifier parameter from external ML tools and load them into global accumulators and for a new phone we collect its graph features and called the user-define scoring function with the classifier parameters and the newly collected features.    CREATE QUERY scoringMethod(vertex<phone> phoneId string inputPath = ""/tmp/lgweight.configure"" string internalClusterFileName = ""/tmp/kMeanWeight_internal.csv"" string externalClusterFileName = ""/tmp/kMeanWeight_external.csv"" bool reloadWeightInfo = false string configFileName = ""/tmp/collectFeatures.config"" bool reloadConfig = false int numOfTopFriends = 5 float abnormalThreshold = 0.5 float advertisementThreshold = 0.5 bool usePrint = true) for graph testGraph returns (ListAccum<float>) {   TYPEDEF tuple<float weight float scale float mean> ParamInfo;   ListAccum<float> @@featureList;   ListAccum<float> @@scoreList;   int isExternal = 0;   int fraudFlag = -1;   static ListAccum<ParamInfo> @@paramInfo0;   static ListAccum<ParamInfo> @@paramInfo1;   static ListAccum<ParamInfo> @@paramInfo2;   static ListAccum<ParamInfo> @@paramInfo3;   static ListAccum<ListAccum<float> > @@InternalCluster;   static ListAccum<ListAccum<float> > @@ExternalCluster;    if (@@paramInfo0.size() == 0 or reloadWeightInfo == true) {     @@paramInfo0.clear();     @@paramInfo0 = {loadAccum(inputPath $0$1$2"""" false)};     @@paramInfo1.clear();     @@paramInfo1 = {loadAccum(inputPath $3$4$5"""" false)};     @@paramInfo2.clear();     @@paramInfo2 = {loadAccum(inputPath $6$7$8"""" false)};     @@paramInfo3.clear();     @@paramInfo3 = {loadAccum(inputPath $9$10$11"""" false)};   }   if (@@InternalCluster.size() == 0 or reloadWeightInfo == true) {     @@InternalCluster.clear();     @@InternalCluster = loadClusterInfo(internalClusterFileName);     @@ExternalCluster.clear();     @@ExternalCluster = loadClusterInfo(externalClusterFileName);   }   //call another gsql query to collect features   @@featureList = collectFeaturesR(phoneId configFileName reloadConfig numOfTopFriends false);    //obtain the last element of featureList which indicates isExternal   isExternal = @@featureList.get(69);   //scoring by calling an user defined expression function.   score(phoneId                   @@featureList                   abnormalThreshold                   advertisementThreshold                   @@paramInfo0                   @@paramInfo1                   @@paramInfo2                   @@paramInfo3                   @@scoreList);   //set the initial scamCluster as -1 which means not a valid scam   @@scoreList += -1;   //Get the fraud flag out   fraudFlag = @@scoreList.get(0);   if (fraudFlag == 3) {     if (isExternal == 0) {       updateScamClusterFlag(@@featureList @@InternalCluster @@scoreList);     } else {       updateScamClusterFlag(@@featureList @@ExternalCluster @@scoreList);     }   }    if (usePrint) {     print @@scoreList;   }   return @@scoreList; }"
1817,Thanks,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1818,a,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1819,lot,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1820,@Bruno,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1821,for,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1822,this,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1823,doc.,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1824,So,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1825,looks,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1826,like,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1827,this,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1828,approach,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1829,is,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1830,splitting,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1831,"""subgraph""",1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1832,snapshots,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1833,into,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1834,time,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1835,range,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1836,buckets,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1837,but,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1838,seems,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1839,hard,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1840,to,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1841,scale,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1842,as,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1843,query,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1844,on,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1845,graph,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1846,can,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1847,be,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1848,any,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1849,time,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1850,range,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1851,based,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1852,on,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1853,timestamp/epoch,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1854,(like,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1855,time,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1856,series,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1857,DB),1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1858,and,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1859,split,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1860,into,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1861,subgraph,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1862,by,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1863,time,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1864,bucket,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1865,could,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1866,be,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1867,lots,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1868,of,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1869,duplicate,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1870,vertex,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1871,and,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1872,edges,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1873,in,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1874,time,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1875,bucket.,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1876,The,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1877,problem,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1878,I,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1879,am,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1880,currently,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1881,facing,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1882,using,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1883,TigerGraph,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1884,is,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1885,-,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1886,how,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1887,to,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1888,model,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1889,geo-temporal,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1890,graph,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1891,so,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1892,can,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1893,make,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1894,time,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1895,and,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1896,geo-based,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1897,query?,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1898,i.e,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1899,each,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1900,of,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1901,vertex,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1902,has,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1903,geographical,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1904,location,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1905,(like,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1906,city,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1907,country),1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1908,and,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1909,each,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1910,vertex,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1911,and,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1912,edges,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1913,also,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1914,changes,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1915,in,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1916,time,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1917,with,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1918,its,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1919,own,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1920,timestamp,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1921,(like,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1922,a,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1923,vertex/edge,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1924,exist,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1925,in,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1926,time,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1927,T1,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1928,and,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1929,not,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1930,exist,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1931,in,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1932,time,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1933,T2).,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1934,There,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1935,are,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1936,numerous,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1937,use,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1938,cases,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1939,like,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1940,search,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1941,flights,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1942,search,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1943,uber/lyft,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1944,rides,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1945,search,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1946,social,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1947,networks,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1948,all,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1949,has,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1950,time,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1951,and,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1952,location,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1953,based,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1954,search,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1955,in,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1956,graph,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1957,but,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1958,seems,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1959,unable,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1960,to,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1961,find,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1962,such,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1963,example,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1964,yet.,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1965,Is,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1966,there,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1967,good,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1968,solution,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1969,example,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1970,of,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1971,time,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1972,and,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1973,geo,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1974,location,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1975,based,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1976,graph,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1977,in,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1978,TigerGraph,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1979,where,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1980,we,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1981,can,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1982,apply,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1983,graph,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1984,algorithms,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1985,based,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1986,on,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1987,interested,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1988,time,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1989,range,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1990,and,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1991,geo,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1992,location,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1993,range?,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1994,Appreciate,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1995,for,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1996,help,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1997,and,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1998,pointers,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
1999,of,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
2000,examples!,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
2001,eric,1763,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,"Thanks a lot @Bruno for this doc.  So looks like this approach is splitting ""subgraph"" snapshots into time range buckets but seems hard to scale as query on graph can be any time range based on timestamp/epoch (like time series DB) and split into subgraph by time bucket could be lots of duplicate vertex and edges in time bucket.  The problem I am currently facing using TigerGraph is - how to model geo-temporal graph so can make time and geo-based query?  i.e each of vertex has geographical location (like city country) and each vertex and edges also changes in time with its own timestamp (like a vertex/edge exist in time T1 and not exist in time T2).   There are numerous use cases like search flights search uber/lyft rides search social networks all has time and location based search in graph but seems unable to find such example yet.  Is there good solution example of time and geo location based graph in TigerGraph where we can apply graph algorithms based on interested time range and geo location range?     Appreciate for help and pointers of examples! eric"
2002,Another,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2003,resource,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2004,around,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2005,TigerGraph,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2006,and,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2007,machine,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2008,learning:,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2009,https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2010,I,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2011,know,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2012,that,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2013,@rik,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2014,is,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2015,building,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2016,ML,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2017,with,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2018,Python,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2019,-,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2020,maybe,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2021,he,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2022,can,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2023,jump,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2024,in,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2025,here,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2026,when,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2027,he,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2028,has,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2029,time.,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2030,Bruno,1762,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Another resource around TigerGraph and machine learning: https://colab.research.google.com/drive/1-Dgl804R_4wEmH4efggCEkhcx6ATGHAU  I know that @rik is building ML with Python - maybe he can jump in here when he has time.  Bruno
2031,Hi,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2032,@eric,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2033,the,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2034,best,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2035,way,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2036,to,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2037,build,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2038,timeseries,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2039,schema,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2040,using,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2041,graph,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2042,database,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2043,would,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2044,be,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2045,to,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2046,put,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2047,the,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2048,date,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2049,part,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2050,into,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2051,a,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2052,vertex,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2053,(or,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2054,multiple,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2055,vertices,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2056,depending,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2057,on,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2058,your,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2059,query,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2060,preferences!),1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2061,and,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2062,to,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2063,connect,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2064,the,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2065,data,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2066,with,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2067,date,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2068,using,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2069,edges.,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2070,That,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2071,way,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2072,you,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2073,will,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2074,be,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2075,able,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2076,to,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2077,make,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2078,a,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2079,very,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2080,fast,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2081,queries,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2082,much,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2083,faster,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2084,than,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2085,filtering,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2086,out,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2087,by,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2088,using,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2089,where,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2090,clause.,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2091,Please,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2092,check,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2093,slides,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2094,11,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2095,and,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2096,12,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2097,in,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2098,this,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2099,document:,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2100,https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2101,Best,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2102,Bruno,1761,https://community.tigergraph.com/t/timeseries-graph-modeling-using-tigergraph/608,Hi @eric  the best way to build timeseries schema using graph database would be to put the date part into a vertex (or multiple vertices depending on your query preferences!) and to connect the data with date using edges. That way you will be able to make a very fast queries much faster than filtering out by using where clause.  Please check slides 11 and 12 in this document: https://drive.google.com/file/d/11YL497fWZwObR1J2qyPb7iIA55sHEiTR/view  Best Bruno
2103,@Bruno,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2104,Thank,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2105,you,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2106,very,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2107,much,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2108,for,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2109,the,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2110,Links.,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2111,I,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2112,have,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2113,seen,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2114,the,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2115,demo,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2116,with,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2117,in,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2118,graph,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2119,ML,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2120,and,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2121,the,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2122,issue,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2123,here,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2124,is,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2125,indeed,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2126,it,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2127,does,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2128,not,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2129,address,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2130,the,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2131,specific,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2132,of,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2133,our,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2134,infrastructure,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2135,which,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2136,rely,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2137,on,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2138,Spark,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2139,ML.,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2140,I,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2141,have,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2142,not,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2143,seen,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2144,the,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2145,deep,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2146,learning,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2147,one.,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2148,But,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2149,ultimately,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2150,what,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2151,i,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2152,am,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2153,specifically,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2154,after,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2155,is:,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2156,how,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2157,as,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2158,claimed,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2159,in,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2160,the,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2161,spark,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2162,tiger,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2163,graph,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2164,integration,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2165,webinar,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2166,can,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2167,you,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2168,store,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2169,the,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2170,parameter,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2171,of,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2172,your,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2173,model,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2174,as,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2175,configuration,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2176,file,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2177,and,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2178,then,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2179,load,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2180,it,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2181,in,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2182,a,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2183,query,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2184,to,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2185,do,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2186,real,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2187,time,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2188,prediction.,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2189,I,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2190,did,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2191,not,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2192,see,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2193,it,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2194,in,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2195,the,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2196,in,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2197,Graph,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2198,ML,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2199,demo.,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2200,It,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2201,is,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2202,just,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2203,that,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2204,specific,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2205,claim,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2206,that,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2207,i,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2208,would,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2209,like,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2210,to,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2211,see,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2212,in,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2213,action,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2214,or,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2215,have,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2216,an,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2217,explanation,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2218,of,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2219,here.,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2220,Will,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2221,check,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2222,the,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2223,deep,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2224,learning,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2225,one,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2226,in,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2227,the,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2228,mean,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2229,time.,1760,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,@Bruno Thank you very much for the Links.   I have seen the demo with in graph ML and the issue here is indeed it does not address the specific of our infrastructure which rely on Spark ML.   I have not seen the deep learning one.    But ultimately what i am specifically after is: how as claimed in the spark tiger graph integration webinar can you store the parameter of your model as configuration file and then load it in a query to do real time prediction. I did not see it in the in Graph ML demo.   It is just that specific claim that i would like to see in action or have an explanation of here.   Will check the deep learning one in the mean time.
2230,Hey,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2231,@Maatdeamon,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2232,there,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2233,is,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2234,a,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2235,nice,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2236,demo,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2237,of,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2238,in,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2239,database,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2240,ML,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2241,in,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2242,our,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2243,Github,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2244,ecosystem:,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2245,https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2246,Also,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2247,you,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2248,can,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2249,find,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2250,Graph,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2251,Gurus,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2252,19,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2253,(deep,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2254,learning),1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2255,script,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2256,here:,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2257,https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2258,They,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2259,are,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2260,not,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2261,based,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2262,on,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2263,Spark,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2264,but,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2265,I,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2266,think,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2267,you,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2268,will,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2269,get,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2270,the,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2271,idea,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2272,how,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2273,to,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2274,use,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2275,ML,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2276,with,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2277,TigerGraph.,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2278,Best,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2279,Bruno,1759,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,Hey @Maatdeamon  there is a nice demo of in database ML in our Github ecosystem: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru28_in-database_ML  Also you can find Graph Gurus 19 (deep learning) script here: https://github.com/tigergraph/ecosys/tree/master/demos/guru_scripts/guru19_deep_learning  They are not based on Spark but I think you will get the idea how to use ML with TigerGraph.  Best Bruno
2280,No,1758,https://community.tigergraph.com/t/graphql-support/592,No plans yet to support GraphQL.
2281,plans,1758,https://community.tigergraph.com/t/graphql-support/592,No plans yet to support GraphQL.
2282,yet,1758,https://community.tigergraph.com/t/graphql-support/592,No plans yet to support GraphQL.
2283,to,1758,https://community.tigergraph.com/t/graphql-support/592,No plans yet to support GraphQL.
2284,support,1758,https://community.tigergraph.com/t/graphql-support/592,No plans yet to support GraphQL.
2285,GraphQL.,1758,https://community.tigergraph.com/t/graphql-support/592,No plans yet to support GraphQL.
2286,This,1757,https://community.tigergraph.com/t/defining-a-graph-schema-via-restpp/125,This is on the roadmap. All GSQL commands will be available via REST. We dont have a confirmed date yet.
2287,is,1757,https://community.tigergraph.com/t/defining-a-graph-schema-via-restpp/125,This is on the roadmap. All GSQL commands will be available via REST. We dont have a confirmed date yet.
2288,on,1757,https://community.tigergraph.com/t/defining-a-graph-schema-via-restpp/125,This is on the roadmap. All GSQL commands will be available via REST. We dont have a confirmed date yet.
2289,the,1757,https://community.tigergraph.com/t/defining-a-graph-schema-via-restpp/125,This is on the roadmap. All GSQL commands will be available via REST. We dont have a confirmed date yet.
2290,roadmap.,1757,https://community.tigergraph.com/t/defining-a-graph-schema-via-restpp/125,This is on the roadmap. All GSQL commands will be available via REST. We dont have a confirmed date yet.
2291,All,1757,https://community.tigergraph.com/t/defining-a-graph-schema-via-restpp/125,This is on the roadmap. All GSQL commands will be available via REST. We dont have a confirmed date yet.
2292,GSQL,1757,https://community.tigergraph.com/t/defining-a-graph-schema-via-restpp/125,This is on the roadmap. All GSQL commands will be available via REST. We dont have a confirmed date yet.
2293,commands,1757,https://community.tigergraph.com/t/defining-a-graph-schema-via-restpp/125,This is on the roadmap. All GSQL commands will be available via REST. We dont have a confirmed date yet.
2294,will,1757,https://community.tigergraph.com/t/defining-a-graph-schema-via-restpp/125,This is on the roadmap. All GSQL commands will be available via REST. We dont have a confirmed date yet.
2295,be,1757,https://community.tigergraph.com/t/defining-a-graph-schema-via-restpp/125,This is on the roadmap. All GSQL commands will be available via REST. We dont have a confirmed date yet.
2296,available,1757,https://community.tigergraph.com/t/defining-a-graph-schema-via-restpp/125,This is on the roadmap. All GSQL commands will be available via REST. We dont have a confirmed date yet.
2297,via,1757,https://community.tigergraph.com/t/defining-a-graph-schema-via-restpp/125,This is on the roadmap. All GSQL commands will be available via REST. We dont have a confirmed date yet.
2298,REST.,1757,https://community.tigergraph.com/t/defining-a-graph-schema-via-restpp/125,This is on the roadmap. All GSQL commands will be available via REST. We dont have a confirmed date yet.
2299,We,1757,https://community.tigergraph.com/t/defining-a-graph-schema-via-restpp/125,This is on the roadmap. All GSQL commands will be available via REST. We dont have a confirmed date yet.
2300,dont,1757,https://community.tigergraph.com/t/defining-a-graph-schema-via-restpp/125,This is on the roadmap. All GSQL commands will be available via REST. We dont have a confirmed date yet.
2301,have,1757,https://community.tigergraph.com/t/defining-a-graph-schema-via-restpp/125,This is on the roadmap. All GSQL commands will be available via REST. We dont have a confirmed date yet.
2302,a,1757,https://community.tigergraph.com/t/defining-a-graph-schema-via-restpp/125,This is on the roadmap. All GSQL commands will be available via REST. We dont have a confirmed date yet.
2303,confirmed,1757,https://community.tigergraph.com/t/defining-a-graph-schema-via-restpp/125,This is on the roadmap. All GSQL commands will be available via REST. We dont have a confirmed date yet.
2304,date,1757,https://community.tigergraph.com/t/defining-a-graph-schema-via-restpp/125,This is on the roadmap. All GSQL commands will be available via REST. We dont have a confirmed date yet.
2305,yet.,1757,https://community.tigergraph.com/t/defining-a-graph-schema-via-restpp/125,This is on the roadmap. All GSQL commands will be available via REST. We dont have a confirmed date yet.
2306,In,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2307,the,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2308,Following,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2309,Webinar,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2310,and,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2311,several,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2312,others,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2313,before,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2314,that,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2315,(Bad,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2316,phone,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2317,call,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2318,detection,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2319,use,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2320,case),1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2321,https://www.youtube.com/watch?v=bPQgRzxZeaw,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2322,(,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2323,Graph,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2324,Gurus,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2325,21:,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2326,Integrating,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2327,Real-Time,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2328,Deep-Link,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2329,Graph,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2330,Analytics,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2331,with,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2332,Spark,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2333,AI),1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2334,It,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2335,is,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2336,receptively,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2337,mentioned,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2338,that,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2339,models,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2340,can,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2341,be,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2342,stored,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2343,back,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2344,in,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2345,Tigergraph,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2346,for,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2347,real,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2348,time,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2349,prediction.,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2350,Do,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2351,you,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2352,have,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2353,example,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2354,of,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2355,how,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2356,this,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2357,is,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2358,done,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2359,?,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2360,An,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2361,example,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2362,of,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2363,a,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2364,model,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2365,function,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2366,or,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2367,whatever,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2368,trained,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2369,in,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2370,Spark,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2371,then,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2372,written,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2373,in,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2374,TigerGraph,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2375,with,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2376,the,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2377,configuration,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2378,file,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2379,for,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2380,the,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2381,parameters,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2382,as,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2383,explained,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2384,in,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2385,the,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2386,several,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2387,webinar,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2388,but,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2389,not,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2390,shown.,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2391,I,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2392,am,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2393,really,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2394,curious,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2395,to,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2396,get,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2397,a,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2398,sense,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2399,of,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2400,how,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2401,this,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2402,is,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2403,actually,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2404,done.,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2405,Many,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2406,thanks,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2407,![Picture,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2408,of,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2409,the,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2410,slide,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2411,of,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2412,the,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2413,webinar,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2414,where,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2415,it,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2416,is,1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
2417,mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg),1756,https://community.tigergraph.com/t/storing-ml-models-in-tigergraph-from-the-spark-tigergraph-integration/614,In the Following Webinar and several others before that (Bad phone call detection use case) https://www.youtube.com/watch?v=bPQgRzxZeaw ( Graph Gurus 21: Integrating Real-Time Deep-Link Graph Analytics with Spark AI) It is receptively mentioned that models can be stored back in Tigergraph for real time prediction.   Do you have example of how this is done ? An example of a model function or whatever trained in Spark then written in TigerGraph with the configuration file for the parameters as explained in the several webinar but not shown.   I am really curious to get a sense of how this is actually done.   Many thanks  ![Picture of the slide of the webinar where it is mentioned](upload://rf8cDT2m9OlKxxne0WC4QrQgmWk.jpeg)
